{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ebef44a",
   "metadata": {},
   "source": [
    "# TAG: Gradient Attack on Transformer-based Language Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a756fc5f",
   "metadata": {},
   "source": [
    "This notebook shows an example for a **short sentence gradient inversion** as described in \"TAG: Gradient Attack on Transformer-based Language Models\". The setting is a BERT-base model and the federated learning algorithm is **fedSGD**.\n",
    "\n",
    "Paper URL: https://aclanthology.org/2021.findings-emnlp.305/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4107d723",
   "metadata": {},
   "source": [
    "#### Abstract\n",
    "Although distributed learning has increasingly gained attention in terms of effectively utilizing local devices for data privacy enhancement, recent studies show that publicly shared gradients in the training process can reveal the private training data (gradient leakage) to a third-party. We have, however, no systematic understanding of the gradient leakage mechanism on the Transformer based language models. In this paper, as the first attempt, we formulate the gradient attack problem on the Transformer-based language models and propose a gradient attack algorithm, TAG, to reconstruct the local training data. Experimental results on Transformer, TinyBERT4, TinyBERT6 BERT_BASE, and BERT_LARGE using GLUE benchmark show that compared with DLG, TAG works well on more weight distributions in reconstructing training data and achieves 1.5x recover rate and 2.5x ROUGE-2 over prior methods without the need of ground truth label. TAG can obtain up to 90% data by attacking gradients in CoLA dataset. In addition, TAG is stronger than previous approaches on larger models, smaller dictionary size, and smaller input length. We hope the proposed TAG will shed some light on the privacy leakage problem in Transformer-based NLP models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90dcd6cb",
   "metadata": {},
   "source": [
    "### Startup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b850eabf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We have to import numpy so we overcome the bug of sementation fault: 11\n",
    "import numpy\n",
    "try:\n",
    "    import breaching\n",
    "except ModuleNotFoundError:\n",
    "    # If there is some issue with the breaching package by pip installing it, it's better to do this as we can make changes to the package internal code.\n",
    "    # You should pull the modified repo at https://github.com/astorfi/breaching\n",
    "    import os; os.chdir(\"..\")\n",
    "    import breaching\n",
    "    \n",
    "import torch\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Redirects logs directly into the jupyter notebook\n",
    "import logging, sys\n",
    "logging.basicConfig(level=logging.INFO, handlers=[logging.StreamHandler(sys.stdout)], format='%(message)s')\n",
    "logger = logging.getLogger()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88d5e214",
   "metadata": {},
   "source": [
    "### Initialize cfg object and system setup:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56bd663b",
   "metadata": {},
   "source": [
    "This will load the full configuration object. This includes the configuration for the use case and threat model as `cfg.case` and the hyperparameters and implementation of the attack as `cfg.attack`. All parameters can be modified below, or overriden with `overrides=` as if they were cmd-line arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a7dc3a48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Investigating use case causal_lang_training with server type honest_but_curious.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'device': device(type='cpu'), 'dtype': torch.float32}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg = breaching.get_config(overrides=[\"case=10_causal_lang_training\",  \"attack=tag\"])\n",
    "          \n",
    "device = torch.device(f'cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "torch.backends.cudnn.benchmark = cfg.case.impl.benchmark\n",
    "setup = dict(device=device, dtype=getattr(torch, cfg.case.impl.dtype))\n",
    "setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "203c5fb1",
   "metadata": {},
   "source": [
    "### Modify config options here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e0764ef",
   "metadata": {},
   "source": [
    "You can use `.attribute` access to modify any of these configurations for the attack, or the case:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ac118ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg.case.user.num_data_points = 1 # How many sentences?\n",
    "cfg.case.user.user_idx = 1 # From which user?\n",
    "cfg.case.data.shape = [16] # This is the sequence length\n",
    "\n",
    "# cfg.attack.optim.max_iterations = 12000 # Increasing the number of iterations can help this attack"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76f64389",
   "metadata": {},
   "source": [
    "### Instantiate all parties"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8db2272f",
   "metadata": {},
   "source": [
    "The following lines generate \"server, \"user\" and \"attacker\" objects and print an overview of their configurations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d3abd955",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reusing dataset wikitext (/Users/k30877/data/wikitext/wikitext-103-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20)\n",
      "Model architecture transformer3 loaded with 10,800,433 parameters and 0 buffers.\n",
      "Overall this is a data ratio of  675027:1 for target shape [1, 16] given that num_queries=1.\n",
      "User (of type UserSingleStep) with settings:\n",
      "    Number of data points: 1\n",
      "\n",
      "    Threat model:\n",
      "    User provides labels: False\n",
      "    User provides buffers: False\n",
      "    User provides number of data points: True\n",
      "\n",
      "    Data:\n",
      "    Dataset: wikitext\n",
      "    user: 1\n",
      "    \n",
      "        \n",
      "Server (of type HonestServer) with settings:\n",
      "    Threat model: Honest-but-curious\n",
      "    Number of planned queries: 1\n",
      "    Has external/public data: False\n",
      "\n",
      "    Model:\n",
      "        model specification: transformer3\n",
      "        model state: default\n",
      "        \n",
      "\n",
      "    Secrets: {}\n",
      "    \n",
      "Attacker (of type OptimizationJointAttacker) with settings:\n",
      "    Hyperparameter Template: tag\n",
      "\n",
      "    Objective: Tag loss with scale=1.0, weight scheme linear, L1 scale 0.1 and task reg=0.0\n",
      "    Regularizers: \n",
      "    Augmentations: \n",
      "\n",
      "    Optimization Setup:\n",
      "        optimizer: bert-adam\n",
      "        signed: None\n",
      "        step_size: 0.05\n",
      "        boxed: False\n",
      "        max_iterations: 1000\n",
      "        step_size_decay: linear\n",
      "        langevin_noise: 0.0\n",
      "        warmup: 50\n",
      "        grad_clip: 1.0\n",
      "        callback: 100\n",
      "        \n"
     ]
    }
   ],
   "source": [
    "user, server, model, loss_fn = breaching.cases.construct_case(cfg.case, setup)\n",
    "attacker = breaching.attacks.prepare_attack(server.model, server.loss, cfg.attack, setup)\n",
    "breaching.utils.overview(server, user, attacker)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "548c0ad6",
   "metadata": {},
   "source": [
    "### Simulate an attacked FL protocol"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2058bcc2",
   "metadata": {},
   "source": [
    "This exchange is a simulation of a single query in a federated learning protocol. The server sends out a `server_payload` and the user computes an update based on their private local data. This user update is `shared_data` and contains, for example, the parameter gradient of the model in the simplest case. `true_user_data` is also returned by `.compute_local_updates`, but of course not forwarded to the server or attacker and only used for (our) analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b0dbd868",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing user update on user 1 in model mode: eval.\n"
     ]
    }
   ],
   "source": [
    "server_payload = server.distribute_payload()\n",
    "shared_data, true_user_data = user.compute_local_updates(server_payload)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "49c68628",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The Tower Building of the Little Rock Arsenal, also known as U.S.\n"
     ]
    }
   ],
   "source": [
    "user.print(true_user_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17255c5a",
   "metadata": {},
   "source": [
    "### Reconstruct user data:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82360c14",
   "metadata": {},
   "source": [
    "Now we launch the attack, reconstructing user data based on only the `server_payload` and the `shared_data`. \n",
    "\n",
    "You can interrupt the computation early to see a partial solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c9a32fd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| It: 1 | Rec. loss: 85.2509 |  Task loss: 10.9858 | T: 0.20s |  Label Entropy: 0.9998.\n",
      "| It: 101 | Rec. loss: 54.8597 |  Task loss: 10.9896 | T: 15.55s |  Label Entropy: 0.8456.\n",
      "| It: 201 | Rec. loss: 28.7863 |  Task loss: 11.2013 | T: 13.59s |  Label Entropy: 0.2058.\n",
      "| It: 301 | Rec. loss: 23.4893 |  Task loss: 11.2264 | T: 13.19s |  Label Entropy: 0.1576.\n",
      "| It: 401 | Rec. loss: 21.9914 |  Task loss: 11.1957 | T: 13.26s |  Label Entropy: 0.1474.\n",
      "| It: 501 | Rec. loss: 21.2840 |  Task loss: 11.1976 | T: 13.86s |  Label Entropy: 0.1409.\n",
      "| It: 601 | Rec. loss: 20.9188 |  Task loss: 11.2102 | T: 13.29s |  Label Entropy: 0.1376.\n",
      "| It: 701 | Rec. loss: 20.2258 |  Task loss: 11.1963 | T: 13.36s |  Label Entropy: 0.1348.\n",
      "| It: 801 | Rec. loss: 20.0509 |  Task loss: 11.1981 | T: 13.34s |  Label Entropy: 0.1327.\n",
      "| It: 901 | Rec. loss: 19.8305 |  Task loss: 11.1950 | T: 13.30s |  Label Entropy: 0.1322.\n",
      "| It: 1000 | Rec. loss: 19.6938 |  Task loss: 11.1984 | T: 13.40s |  Label Entropy: 0.1315.\n",
      "Optimal candidate solution with rec. loss 25.8748 selected.\n"
     ]
    }
   ],
   "source": [
    "reconstructed_user_data, stats = attacker.reconstruct([server_payload], [shared_data], {}, dryrun=cfg.dryrun)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dc4943f",
   "metadata": {},
   "source": [
    "Next we'll evaluate metrics, comparing the `reconstructed_user_data` to the `true_user_data`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "31f2685a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't find file locally at /Users/k30877/github/breaching/google_bleu/google_bleu.py, or remotely at https://raw.githubusercontent.com/huggingface/datasets/1.11.0/metrics/google_bleu/google_bleu.py.\n",
      "The file was picked from the master branch on github instead at https://raw.githubusercontent.com/huggingface/datasets/master/metrics/google_bleu/google_bleu.py.\n",
      "METRICS: | Accuracy: 0.5000 | S-BLEU: 0.14 | FMSE: 4.1785e-02 | \n",
      " G-BLEU: 0.26 | ROUGE1: 0.64| ROUGE2: 0.26 | ROUGE-L: 0.48| Token Acc: 68.75% | Label Acc: 6.25%\n"
     ]
    }
   ],
   "source": [
    "metrics = breaching.analysis.report(reconstructed_user_data, true_user_data, [server_payload], \n",
    "                                    server.model, order_batch=True, compute_full_iip=False, \n",
    "                                    cfg_case=cfg.case, setup=setup)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a200797e",
   "metadata": {},
   "source": [
    "And finally, we also print the reconstructed data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "631f4a84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The Towerdefine (', Little Rock Arsenal U also known domination the.sl twent\n"
     ]
    }
   ],
   "source": [
    "user.print(reconstructed_user_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dcb085f",
   "metadata": {},
   "source": [
    "### Notes:\n",
    "* Sentence classification is a better scenario for TAG than e.g. next-token prediction. This is because the attack has to recover the label in addition to the input sentence. For COLA, this is just a binary choice, but for a next-token prediction, the \"label\" space is the entire vocabulary.\n",
    "* `huggingface` needs an internet connection for metrics, datasets and tokenizers. After caching these objects, it can be turned to offline mode with `cfg.case.impl.enable_huggingface_offline_mode=True`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
